{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Global settings"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pickle\n",
    "import datetime\n",
    "import torch\n",
    "import random\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import plotly.graph_objects as go\n",
    "\n",
    "from plotly.subplots import make_subplots\n",
    "from sklearn.model_selection import KFold\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "\n",
    "from slim_gsgp.datasets.data_loader import *\n",
    "from slim_gsgp.main_gsgp import gsgp\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Settings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "seed = 1111\n",
    "np.random.seed(seed)\n",
    "random.seed(seed)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_color = 'blue'\n",
    "test_color = 'orange'\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br />\n",
    "\n",
    "## Data simulation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "$$\n",
    "f(X) = x_1^2 + x_2^2 + x_3^2 + x_1 x_2 x_3 + N(0, 1)\n",
    "$$\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_samples = 100\n",
    "\n",
    "feature_1 = np.random.uniform(-10, 10, size=n_samples)\n",
    "feature_2 = np.random.normal(0, 5, size=n_samples)\n",
    "feature_3 = np.random.beta(2, 5, size=n_samples) * 20\n",
    "noise = np.random.normal(0, 1, size=n_samples)\n",
    "\n",
    "target = (\n",
    "    feature_1**2 + feature_2**2 + feature_3**2 + \n",
    "    feature_1 * feature_2 * feature_3 +\n",
    "    np.exp(feature_1) +\n",
    "    noise\n",
    ")\n",
    "\n",
    "df = pd.DataFrame({\n",
    "    'feature_1': feature_1,\n",
    "    'feature_2': feature_2,\n",
    "    'feature_3': feature_3,\n",
    "    'target': target\n",
    "})\n",
    "\n",
    "df.head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Cross-validation objects"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv = KFold(n_splits=10, random_state=seed, shuffle=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr />\n",
    "\n",
    "# GSGP"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 1: Problem Instance definition\n",
    "\n",
    "- `X` and `y`: which dataset will be used?\n",
    "- `fitnesss_function`: the fitness function that will be used to measure the algorithm learning.\n",
    "- `minimization`: is this a minimization problem?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# DATASET = 'syn'\n",
    "# DATASET = 'boston'\n",
    "DATASET = 'bike'\n",
    "\n",
    "if DATASET == 'syn':\n",
    "    X = torch.tensor(df.values[:, :3], dtype=torch.float32)\n",
    "    y = torch.tensor(df.values[:, 3], dtype=torch.float32)\n",
    "    DATASET_NAME = 'Synthetic'\n",
    "elif DATASET == 'boston':\n",
    "    X, y = load_boston(X_y=True)\n",
    "    DATASET_NAME = 'Boston'\n",
    "elif DATASET == 'bike':\n",
    "    X, y = load_bike_sharing(X_y=True)\n",
    "    # X = X[:, :11]\n",
    "    DATASET_NAME = 'Bike'\n",
    "\n",
    "FITNESS_FUNCTION = 'rmse'\n",
    "MINIMIZATION = True\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_cv = [[train_ix, test_ix] for train_ix, test_ix in cv.split(X, y)][0]\n",
    "\n",
    "# Train and test split\n",
    "X_train_tensor = X[data_cv[0], :]\n",
    "y_train_tensor = y[data_cv[0]]\n",
    "X_val_tensor = X[data_cv[1], :]\n",
    "y_val_tensor = y[data_cv[1]]\n",
    "\n",
    "[X_train_tensor.shape, y_train_tensor.shape, X_val_tensor.shape, y_val_tensor.shape]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 2: Search space definition\n",
    "\n",
    "- `initializer`: how new random trees are initialized. See [`slim_gsgp` initializers](https://github.com/DALabNOVA/slim/blob/main/slim_gsgp/initializers/initializers.py);\n",
    "- `tree_constants`: the constants to be used in the terminal set;\n",
    "- `tree_functions`: the function set (tree internal nodes);\n",
    "- `prob_const`: the probability for choosing constants instead of dataset features on tree terminals;\n",
    "- `init_depth`: max depth for tree initialisation;\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "INITIALIZER = 'rhh'\n",
    "TREE_CONSTANTS = [random.uniform(0, 1) for _ in range(9)]+[ -1.]\n",
    "TREE_FUNCTIONS = ['add', 'subtract']\n",
    "PROB_CONSTANT = 0.9\n",
    "MAX_INIT_DEPTH = 4\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "TREE_CONSTANTS\n",
    "# [0.21760077176688164,\n",
    "#  0.3443807346030824,\n",
    "#  0.6422536234699076,\n",
    "#  0.36413206493253214,\n",
    "#  0.08358916437841302,\n",
    "#  0.5040914040192876,\n",
    "#  0.18743462930144428,\n",
    "#  0.8842252761132199,\n",
    "#  0.33821341140965044,\n",
    "#  -1.0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 3: GSGP Instance\n",
    "\n",
    "The following hyperparameter options are the same as for GP:\n",
    "\n",
    "- `pop_size`: the size of the population of candidate solutions.\n",
    "- `p_xo`: the probability of applying the cross-over genetic operator to candidate solutions.\n",
    "- `elitism`: should the elite(s) be preserved at each generation?\n",
    "- `n_elits`: if using elitism, how many solutions should be kept?\n",
    "- Selection method. Only tournament selection in available on `slim_gsgp` libraya, as this is the most commonly used. It requires the definition of the `tournament_size` hyperparameter: how many solutions should participate in the tournament of tournament selection?\n",
    "\n",
    "**Additionally, GSGP requires:**\n",
    "\n",
    "- `ms_lower`: lower bound for generating the random number used as mutation step.\n",
    "- `ms_upper`: upper bound for generating the random number used as mutation step.\n",
    "- `reconstruct`: whether to store the structure of individuals.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "POP_SIZE = 1000\n",
    "P_XO = 0.9\n",
    "ELISTISM = True\n",
    "N_ELITES = 2\n",
    "TOURNAMENT_SIZE = int(POP_SIZE*0.07)\n",
    "print(f'TOURNAMENT_SIZE: {TOURNAMENT_SIZE}')\n",
    "\n",
    "MS_LOWER = 0\n",
    "MS_UPPER = 1\n",
    "RECONSTRUCT = True\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 4: Solve settings\n",
    "\n",
    "Same as available for GP:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "GENERATIONS = 10\n",
    "VERBOSE = 1\n",
    "\n",
    "LOG_LEVEL = 2\n",
    "LOG_DIR = './log/PC3/'\n",
    "LOG_PATH = LOG_DIR+'gsgp_'+DATASET_NAME+'.csv'\n",
    "\n",
    "if not os.path.exists(LOG_DIR):\n",
    "    os.makedirs(LOG_DIR)\n",
    "\n",
    "if os.path.exists(LOG_PATH):\n",
    "    os.remove(LOG_PATH)\n",
    "\n",
    "print(f'Total evaluations: {POP_SIZE*GENERATIONS}\\n')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Solve "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = gsgp(\n",
    "    # ---\n",
    "    # Search Space\n",
    "    init_depth=MAX_INIT_DEPTH,\n",
    "    # max_depth=MAX_DEPTH,\n",
    "    tree_constants=TREE_CONSTANTS,\n",
    "    tree_functions=TREE_FUNCTIONS,\n",
    "    prob_const = PROB_CONSTANT,\n",
    "    # --\n",
    "    # Problem Instance\n",
    "    X_train=X_train_tensor, y_train=y_train_tensor, \n",
    "    X_test=X_val_tensor, y_test=y_val_tensor,\n",
    "    dataset_name=DATASET_NAME,\n",
    "    fitness_function=FITNESS_FUNCTION,\n",
    "    minimization=MINIMIZATION,\n",
    "    # --\n",
    "    # GSGP instance \n",
    "    pop_size=POP_SIZE,\n",
    "    p_xo = P_XO,\n",
    "    initializer=INITIALIZER,\n",
    "    tournament_size = TOURNAMENT_SIZE,\n",
    "    ms_lower = MS_LOWER,\n",
    "    ms_upper = MS_UPPER,\n",
    "    reconstruct = RECONSTRUCT,\n",
    "    # ---\n",
    "    # Solve settings\n",
    "    n_iter=GENERATIONS,\n",
    "    elitism=ELISTISM,\n",
    "    n_elites=N_ELITES,\n",
    "    test_elite=True,\n",
    "    log_path=LOG_PATH,\n",
    "    log_level=LOG_LEVEL,\n",
    "    verbose=VERBOSE,\n",
    "    n_jobs=1,\n",
    "    seed=seed\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Log level 2\n",
    "# -----------\n",
    "# 0  - Algorithm\n",
    "# 1  - Instance ID\n",
    "# 2  - Dataset\n",
    "# 3  - Seed\n",
    "# 4  - Generation\n",
    "# 5  - Fitness\n",
    "# 6  - Running time\n",
    "# 7  - Population nodes\n",
    "# 8  - Test fitness\n",
    "# 9  - Elite nodes\n",
    "# 10 - Genotype diversity: gsgp_pop_div_from_vectors (Calculate the diversity of a population from semantic vectors)\n",
    "# 11 - Phenotype diversity: sd(pop.fit)\n",
    "# 12 - Log level\n",
    "pd.read_csv(LOG_PATH, header=None).head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = go.Figure()\n",
    "fig.add_trace(go.Scatter(y=pd.read_csv(LOG_PATH, header=None).iloc[:,5].values, \n",
    "                         mode='lines', name='Train', line=dict(color=train_color)))\n",
    "fig.add_trace(go.Scatter(y=pd.read_csv(LOG_PATH, header=None).iloc[:,8].values, \n",
    "                         mode='lines', name='Test', line=dict(color=test_color)))\n",
    "fig.update_layout(\n",
    "    height=400, width=800, \n",
    "    margin=dict(t=50),\n",
    "    title_text='GSGP - Train vs Test Fitness ('+DATASET_NAME+' dataset)',\n",
    "    xaxis_title='Generation', yaxis_title='RMSE'\n",
    ")\n",
    "fig.update_yaxes(range=[0, None])\n",
    "fig.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = go.Figure()\n",
    "fig.add_trace(go.Scatter(y=pd.read_csv(LOG_PATH, header=None).iloc[:,9].values, \n",
    "                         mode='lines', name='Train', line=dict(color=train_color)))\n",
    "fig.update_layout(\n",
    "    height=400, width=800, \n",
    "    margin=dict(t=50),\n",
    "    title_text='GSGP - Solution size ('+DATASET_NAME+' dataset)',\n",
    "    # yaxis_type='log',\n",
    "    xaxis_title='Generation', yaxis_title='Nodes count'\n",
    ")\n",
    "fig.update_yaxes(range=[0, None])\n",
    "fig.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = go.Figure()\n",
    "div_vector_log = pd.read_csv(LOG_PATH, header=None).iloc[:,10].values\n",
    "div_vector_values = np.array([float(x.replace('tensor(', '').replace(')', '')) for x in div_vector_log])\n",
    "fig.add_trace(go.Scatter(y=div_vector_values,\n",
    "                         mode='lines', name='Train', line=dict(color=train_color)))\n",
    "fig.update_layout(\n",
    "    height=400, width=800, \n",
    "    margin=dict(t=50),\n",
    "    title_text='GSGP - Population Semantic Diversity ('+DATASET_NAME+' dataset)',\n",
    "    yaxis_range=[0,None],\n",
    "    xaxis_title='Generation', yaxis_title='Semantic Diversity'\n",
    ")\n",
    "fig.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = go.Figure()\n",
    "fig.add_trace(go.Scatter(y=pd.read_csv(LOG_PATH, header=None).iloc[:,11].values, \n",
    "                         mode='lines', name='Train', line=dict(color=train_color)))\n",
    "fig.update_layout(\n",
    "    height=400, width=800, \n",
    "    margin=dict(t=50),\n",
    "    yaxis_range=[0,None],\n",
    "    title_text='GSGP - Population Fitness Diversity ('+DATASET_NAME+' dataset)',\n",
    "    xaxis_title='Generation', yaxis_title='Fitness Standard Deviation'\n",
    ")\n",
    "fig.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model.predict(X_val_tensor)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "[model.fitness, model.test_fitness]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.nodes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from slim_gsgp.algorithms.GSGP.representations.tree import Tree\n",
    "def print_nested_list(nested_list):\n",
    "    if isinstance(nested_list, list):\n",
    "        if nested_list[0].__name__ == 'geometric_crossover':\n",
    "            # T1 * TR\n",
    "            print_nested_list(nested_list[1])\n",
    "            print(' * ', end = '')\n",
    "            print_nested_list(nested_list[3])\n",
    "\n",
    "            # + T2 * 1 - TR)\n",
    "            print(' + ', end = '')\n",
    "            print_nested_list(nested_list[2])\n",
    "            print(' * (1 - ', end = '')\n",
    "            print_nested_list(nested_list[3])\n",
    "            print(')\\n')\n",
    "            \n",
    "        elif nested_list[0].__name__ == 'standard_geometric_mutation':\n",
    "            # T \n",
    "            print_nested_list(nested_list[1])\n",
    "\n",
    "            # + ms\n",
    "            print(' + (', end = '')\n",
    "            print(nested_list[4], end='')\n",
    "            \n",
    "            # * ( TR1 - TR 2 )\n",
    "            print(' * (', end = '')\n",
    "            print_nested_list(nested_list[2])\n",
    "            print(' - ', end = '')\n",
    "            print_nested_list(nested_list[3])\n",
    "            print(')')\n",
    "    elif isinstance(nested_list, tuple):\n",
    "        print(nested_list)\n",
    "    else:\n",
    "        if isinstance(nested_list.structure, tuple):\n",
    "            print(nested_list.structure, end='')\n",
    "        else:\n",
    "            print_nested_list(nested_list.structure)\n",
    "\n",
    "if RECONSTRUCT:\n",
    "    print_nested_list(model.structure)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br />\n",
    "<hr />\n",
    "\n",
    "# Exercises (not graded)\n",
    "\n",
    "- Experiment different synthetic datasets.\n",
    "- Run the nested crossvalidation for hyperparameters tunning using the Boston dataset.\n",
    "\n",
    "<br />"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.12",
   "language": "python",
   "name": "xai_clustering"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
