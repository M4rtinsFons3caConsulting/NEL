{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "43814b1b-bd1c-4905-bf68-999ff0587ca8",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47c0fc76-001c-44d2-a5f8-910bb8decdfc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import scikit_posthocs as sp\n",
    "import plotly.express as px\n",
    "import plotly.graph_objects as go\n",
    "\n",
    "from sklearn.datasets import fetch_openml\n",
    "from sklearn.model_selection import GridSearchCV, cross_val_score, KFold\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.metrics import mean_squared_error, make_scorer\n",
    "from scipy.stats import wilcoxon, friedmanchisquare\n",
    "import scikit_posthocs as sp\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Random seed\n",
    "seed = 1\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "726c042d-938b-4c4b-add1-d3a179e99118",
   "metadata": {},
   "source": [
    "# Data split approaches"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "204f47f3-d948-48cc-a6ae-cf1b333164e2",
   "metadata": {},
   "source": [
    "| Method                  | Stability     | Risk of Overfitting | Computational Cost | Recommended Use Case                          |\n",
    "|-------------------------|---------------|----------------------|--------------------|-----------------------------------------------|\n",
    "| **Random Split**        | Low           | High                 | Low                | Fast prototyping, quick checks                |\n",
    "| **Cross-Validation**    | Medium        | Medium               | Medium             | Reliable model evaluation                     |\n",
    "| **Nested Cross-Validation** | High     | Low                  | High               | Final evaluation, rigorous comparisons        |\n",
    "\n",
    "<br />"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b70a915-0b4b-4791-9250-1c397d34ea14",
   "metadata": {},
   "source": [
    "# Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d7162fe-03c5-4580-85f4-b216218cf70e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the Boston dataset from OpenML\n",
    "boston = fetch_openml(name='boston', version=1, as_frame=True)\n",
    "X = boston.data\n",
    "y = boston.target.astype(float)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8aedbb8f-3934-4698-9e19-118390ff8308",
   "metadata": {},
   "source": [
    "# Nested Cross-validation scheme\n",
    "\n",
    "The [KFold method](https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.KFold.html) from `scikit-learn` will be used to k-fold cross-validation splitting.\n",
    "\n",
    "However, it will not always be possible to use this method. In such cases, you should implement your own outer and inner cross-validation loops.\n",
    "\n",
    "<br />"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08d28d27-68fc-4a8e-bc31-df71531298cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "k_outer = 10\n",
    "k_inner = 5\n",
    "# https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.KFold.html\n",
    "outer_cv = KFold(n_splits=k_outer, shuffle=True, random_state=seed)\n",
    "inner_cv = KFold(n_splits=k_inner, shuffle=True, random_state=seed)\n",
    "\n",
    "total_instances = X.shape[0]\n",
    "outer_test_size = total_instances // k_outer\n",
    "outer_train_size = total_instances - outer_test_size\n",
    "inner_val_size = outer_train_size // k_inner\n",
    "inner_train_size = outer_train_size - inner_val_size\n",
    "\n",
    "print(f'Total Instances:\\t{total_instances}\\n--')\n",
    "print(f'Outer Train set:\\t{outer_train_size}')\n",
    "print(f'Test set:\\t\\t{outer_test_size}\\n--')\n",
    "print(f'Inner Train set:\\t{inner_train_size}')\n",
    "print(f'Validation set:\\t\\t{inner_val_size}\\n')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bec8fda0-0326-42da-b2e1-c47142b7d6f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# CV Evaluation\n",
    "def negative_rmse(y_true, y_pred):\n",
    "    \"\"\"Calculates the negative of the Root Mean Squared Error (RMSE).\n",
    "        Args:\n",
    "            y_true: True values\n",
    "            y_pred: Predicted values\n",
    "        Returns:\n",
    "            float: The negative value of the RMSE. It returns negative because the\n",
    "                   scoring functions in Scikit-learn aim to maximize the score.\n",
    "                   Maximizing -RMSE is equivalent to minimizing RMSE.\n",
    "    \"\"\"\n",
    "    return -np.sqrt(mean_squared_error(y_true, y_pred))\n",
    "scoring_neg = make_scorer(negative_rmse)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "857e27d7-40a2-4cfb-a62f-995079433caf",
   "metadata": {},
   "source": [
    "# Models and search spaces"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d0df448-f4ad-478a-9e73-9df2799ef5bc",
   "metadata": {},
   "source": [
    "The **Support Vector Regressor (SVR)** and **Random Forest Regressor (RF)** models will be used in this class to explore cross-validation and nested cross-validation approaches.\n",
    "\n",
    "- The **SVR** model requires **data scaling**, so it will be wrapped in a **Pipeline**.\n",
    "- For **SVR**, the hyperparameters to be tuned are:\n",
    "    - **C** (regularization strength)\n",
    "    - **gamma** (kernel coefficient for some kernels)\n",
    "    - **kernel** (e.g., 'linear', 'rbf')\n",
    "- For **RF**, the hyperparameters to be tuned are:\n",
    "    - **n_estimators** (number of trees in the forest)\n",
    "    - **max_depth** (maximum depth of each tree)\n",
    "    - **max_features** (number of features to consider when looking for the best split)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3eb9f5ff-c706-4541-8997-cdefe3b3c935",
   "metadata": {},
   "outputs": [],
   "source": [
    "# SVM pipeline\n",
    "svm_pipeline = Pipeline([\n",
    "    ('scaler', StandardScaler()),\n",
    "    ('svr', SVR())\n",
    "])\n",
    "svm_param_grid = {\n",
    "    'svr__C': [0.1, 1, 10],\n",
    "    'svr__gamma': ['scale', 'auto'],\n",
    "    'svr__kernel': ['rbf', 'linear']\n",
    "}\n",
    "\n",
    "# Random Forest direct grid\n",
    "rf_model = RandomForestRegressor(random_state=seed)\n",
    "rf_param_grid = {\n",
    "    'n_estimators': [2, 3],\n",
    "    'max_depth': [2, 3],\n",
    "    'max_features': [None, 'sqrt']\n",
    "}\n",
    "\n",
    "# Significance tests\n",
    "alpha_sig = 0.05\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c44f105c-190d-4046-8408-ae1a27ca434d",
   "metadata": {},
   "source": [
    "<br />\n",
    "<hr />\n",
    "\n",
    "# Nested CV loop\n",
    "\n",
    "The cross-validation grid search will be done with the [GridSearchCV method](https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.GridSearchCV.html) from `scikit-learn`, with **fixed grid search** and a **fixed number of iterations**.\n",
    "\n",
    "For a more detailed instructions on how to use the `GridSearchCV` method, check its [user manual](https://scikit-learn.org/stable/modules/grid_search.html#grid-search).\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a9c590a-a12e-4a49-86c2-8357eb26d160",
   "metadata": {},
   "source": [
    "<br />\n",
    "\n",
    "## SVM and RF deterministic hyperparameters choice"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e48dd63-1ef7-4e98-9969-429f55c9b0c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# SVM Nested CV\n",
    "#\n",
    "# The GridSearchCV searches over specified parameter values for an estimator\n",
    "svm_grid = GridSearchCV(estimator=svm_pipeline, param_grid=svm_param_grid, cv=inner_cv, scoring=scoring_neg)\n",
    "#\n",
    "# The cross_val_score evaluates the model using different splits of the data and returns the performance scores\n",
    "# using the best parameters found in the grid search\n",
    "svm_scores = cross_val_score(svm_grid, X, y, cv=outer_cv, scoring=scoring_neg)\n",
    "\n",
    "# Random Forest Nested CV\n",
    "rf_grid = GridSearchCV(estimator=rf_model, param_grid=rf_param_grid, cv=inner_cv, scoring=scoring_neg)\n",
    "rf_scores = cross_val_score(rf_grid, X, y, cv=outer_cv, scoring=scoring_neg)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f9c93b5-9aca-4f48-a2d6-b9047c2c586d",
   "metadata": {},
   "source": [
    "## Comparing models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "431d9fa2-7302-491d-ab94-a3eac2a4937f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Global significance test\n",
    "df_test_set = pd.DataFrame({\n",
    "    'Model': ['SVM'] * len(svm_scores) + ['RF'] * len(rf_scores),\n",
    "    'RMSE': np.concatenate((-svm_scores, -rf_scores))\n",
    "})\n",
    "stat, p = stat, p_value = wilcoxon(-svm_scores, -rf_scores)\n",
    "print(f'\\nWilcoxon test statistic: {stat:.4f}, p-value: {p:.4f}')\n",
    "\n",
    "# Boxplots\n",
    "fig = go.Figure()\n",
    "fig.add_trace(go.Box(\n",
    "    x=df_test_set['Model'],\n",
    "    y=df_test_set['RMSE'],\n",
    "    fillcolor='rgba(108, 140, 200, 0.3)',\n",
    "    line=dict(color='rgba(108, 140, 200, 1)'),\n",
    "    boxpoints='all',\n",
    "    jitter=0,\n",
    "    pointpos=0,\n",
    "    marker=dict(color='rgba(108, 140, 200, 1)')\n",
    "))\n",
    "fig.update_yaxes(range=[0, max(df_test_set['RMSE'])*1.05])\n",
    "fig.update_layout(\n",
    "    title='SVM vs. RF', yaxis_title='Test RMSE',\n",
    "    width=500, height=300,\n",
    "    plot_bgcolor='#f1f1f1',\n",
    "    margin=dict(l=50, r=50, t=75, b=20),\n",
    "    showlegend=False\n",
    ")\n",
    "fig.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1398cfa8-281d-426d-b134-c2a5d5587ffc",
   "metadata": {},
   "source": [
    "<hr />\n",
    "<br />\n",
    "\n",
    "## SVM statistical hyperparameter analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59a52c7c-491c-474b-bc98-eb49117ef7c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "best_grid_models = []\n",
    "validation_results = {'svm':[]}\n",
    "i_outer = 0\n",
    "for train_idx, test_idx in outer_cv.split(X, y):\n",
    "    print('\\n\\n----------\\nOuter CV {}'.format(i_outer))\n",
    "\n",
    "    # Outer CV (test set) -------------------------------------------------\n",
    "    X_train, X_test = X.iloc[train_idx], X.iloc[test_idx]\n",
    "    y_train, y_test = y.iloc[train_idx], y.iloc[test_idx]\n",
    "\n",
    "    # Inner CV (validation set for hyperparameters tuning) ----------------\n",
    "    # SVM\n",
    "    grid_search = GridSearchCV(estimator=svm_pipeline, \n",
    "                    param_grid=svm_param_grid, \n",
    "                    cv=inner_cv, \n",
    "                    scoring=scoring_neg)\n",
    "    grid_search.fit(X_train, y_train)\n",
    "    \n",
    "    # Grid CV automated model selection\n",
    "    best_model = grid_search.best_estimator_\n",
    "    best_grid_models.append({\n",
    "        'C': grid_search.best_params_['svr__C'],\n",
    "        'gamma': grid_search.best_params_['svr__gamma'],\n",
    "        'kernel': grid_search.best_params_['svr__kernel']\n",
    "    })\n",
    "    print('Best model hyperparameters:\\n\\tC\\t{}\\n\\tgamma\\t{}\\n\\tkernel\\t{}'.format(\n",
    "        best_model.get_params()['svr__C'], best_model.get_params()['svr__gamma'], best_model.get_params()['svr__kernel']\n",
    "    ))\n",
    "    \n",
    "    # Statistical tests to analyse best hyperparameter combination --------\n",
    "    # Retrieve results\n",
    "    df = []\n",
    "    for i_cv in range(k_inner):\n",
    "        res = {}\n",
    "        for i_par in range(len(grid_search.cv_results_['split'+str(i_cv)+'_test_score'])):\n",
    "            res.update({'par_'+str(i_par): grid_search.cv_results_['split'+str(i_cv)+'_test_score'][i_par]})\n",
    "        df.append(res)\n",
    "    df = pd.DataFrame(df)\n",
    "    validation_results['svm'].append(df.iloc[:, list(grid_search.cv_results_['rank_test_score']).index(1)])\n",
    "    \n",
    "    # Global significance test\n",
    "    stat, p = friedmanchisquare(*[df[col] for col in df.columns])\n",
    "    print(f'\\nFriedman test statistic: {stat:.4f}, p-value: {p:.4f}')\n",
    "    if(p<alpha_sig):\n",
    "        # Pairwise significance test\n",
    "        posthoc_result = sp.posthoc_nemenyi_friedman(df.to_numpy())\n",
    "        significant_columns = posthoc_result.columns[posthoc_result.lt(0.05).any(axis=0)]\n",
    "        df_significant = df.iloc[:, list(significant_columns)]\n",
    "        # P-values\n",
    "        filtered_result = posthoc_result[posthoc_result < alpha_sig]\n",
    "        filtered_result = filtered_result.dropna(how='all').dropna(axis=1, how='all')\n",
    "        filtered_result = filtered_result.fillna('-')\n",
    "        print('P-values of significant differences:')\n",
    "        display(filtered_result)\n",
    "    else:\n",
    "        print('No significant differences found.')        \n",
    "\n",
    "    # Boxplots\n",
    "    df_long = df.melt(var_name='group', value_name='score')\n",
    "    label_map = {\n",
    "        f'par_{i}': f'[par_{i}] C {param['svr__C']}<br>gamma: {param['svr__gamma']}<br>kernel: {param['svr__kernel']}'\n",
    "        for i, param in enumerate(grid_search.cv_results_['params'])\n",
    "    }\n",
    "    df_long['label'] = df_long['group'].map(label_map)\n",
    "    fig = go.Figure()\n",
    "    fig.add_trace(go.Box(\n",
    "        x=df_long['label'],\n",
    "        y=-df_long['score'],\n",
    "        fillcolor='rgba(108, 140, 200, 0.3)',\n",
    "        line=dict(color='rgba(108, 140, 200, 1)'),\n",
    "        boxpoints='all',\n",
    "        jitter=0,\n",
    "        pointpos=0,\n",
    "        marker=dict(color='rgba(108, 140, 200, 1)')\n",
    "    ))\n",
    "    fig.update_layout(\n",
    "        title='CV '+str(i_outer), yaxis_title='Validation Fitness',\n",
    "        width=1000, height=400,\n",
    "        plot_bgcolor='#f1f1f1',\n",
    "        xaxis_tickangle=-90,\n",
    "        margin=dict(l=50, r=50, t=50, b=20),\n",
    "        showlegend=False\n",
    "    )\n",
    "    fig.show()\n",
    "\n",
    "    # Outer CV update\n",
    "    i_outer +=1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa9ad467-c779-43c4-a029-2c0b54a2ef80",
   "metadata": {},
   "outputs": [],
   "source": [
    "best_grid_models"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "832ba7d7-469c-4bab-9e13-6d480e191e8a",
   "metadata": {},
   "source": [
    "## RF with statistical hyperparameter analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "612b42bb-69fa-438a-a4de-376cbf62b53f",
   "metadata": {},
   "outputs": [],
   "source": [
    "best_grid_models = []\n",
    "validation_results.update({'rf': []})\n",
    "i_outer = 0\n",
    "for train_idx, test_idx in outer_cv.split(X, y):\n",
    "    print('\\n\\n----------\\nOuter CV {}'.format(i_outer))\n",
    "\n",
    "    # Outer CV (test set) -------------------------------------------------\n",
    "    X_train, X_test = X.iloc[train_idx], X.iloc[test_idx]\n",
    "    y_train, y_test = y.iloc[train_idx], y.iloc[test_idx]\n",
    "\n",
    "    # Inner CV (validation set for hyperparameters tuning) ----------------\n",
    "    # Random Forest\n",
    "    grid_search = GridSearchCV(estimator=rf_model, \n",
    "                    param_grid=rf_param_grid, \n",
    "                    cv=inner_cv, \n",
    "                    scoring=scoring_neg)\n",
    "    grid_search.fit(X_train, y_train)\n",
    "    \n",
    "    # Grid CV automated model selection\n",
    "    best_model = grid_search.best_estimator_\n",
    "    best_grid_models.append({\n",
    "        'max_depth': grid_search.best_params_['max_depth'],\n",
    "        'max_features': grid_search.best_params_['max_features'],\n",
    "        'n_estimators': grid_search.best_params_['n_estimators']\n",
    "    })\n",
    "    print('Best model hyperparameters:\\n\\tmax_depth\\t{}\\n\\tmax_features\\t{}\\n\\tn_estimators\\t{}'.format(\n",
    "        best_model.get_params()['max_depth'], best_model.get_params()['max_features'], best_model.get_params()['n_estimators']\n",
    "    ))\n",
    "    \n",
    "    # Statistical tests to analyse best hyperparameter combination --------\n",
    "    # Retrieve results\n",
    "    df = []\n",
    "    for i_cv in range(k_inner):\n",
    "        res = {}\n",
    "        for i_par in range(len(grid_search.cv_results_['split'+str(i_cv)+'_test_score'])):\n",
    "            res.update({'par_'+str(i_par): grid_search.cv_results_['split'+str(i_cv)+'_test_score'][i_par]})\n",
    "        df.append(res)\n",
    "    df = pd.DataFrame(df)\n",
    "    validation_results['rf'].append(df.iloc[:, list(grid_search.cv_results_['rank_test_score']).index(1)])\n",
    "    \n",
    "    # Global significance test    \n",
    "    stat, p = friedmanchisquare(*[df[col] for col in df.columns])\n",
    "    print(f'\\nFriedman test statistic: {stat:.4f}, p-value: {p:.4f}')\n",
    "    if(p<alpha_sig):\n",
    "        # Pairwise significance test\n",
    "        # Pairwise significance test\n",
    "        posthoc_result = sp.posthoc_nemenyi_friedman(df.to_numpy())\n",
    "        significant_columns = posthoc_result.columns[posthoc_result.lt(0.05).any(axis=0)]\n",
    "        df_significant = df.iloc[:, list(significant_columns)]\n",
    "        # P-values\n",
    "        filtered_result = posthoc_result[posthoc_result < alpha_sig]\n",
    "        filtered_result = filtered_result.dropna(how='all').dropna(axis=1, how='all')\n",
    "        filtered_result = filtered_result.fillna('-')\n",
    "        print('P-values of significant differences:')\n",
    "        display(filtered_result)\n",
    "    else:\n",
    "        print('No significant differences found.')\n",
    "    \n",
    "    # Boxplots\n",
    "    df_long = df.melt(var_name='group', value_name='score')\n",
    "    label_map = {\n",
    "        f'par_{i}': f'mx_depth: {param['max_depth']}<br>mx_feat: {param['max_features']}<br>n_est: {param['n_estimators']}'\n",
    "        for i, param in enumerate(grid_search.cv_results_['params'])\n",
    "    }\n",
    "    df_long['label'] = df_long['group'].map(label_map)\n",
    "    \n",
    "    fig = go.Figure()\n",
    "    fig.add_trace(go.Box(\n",
    "        x=df_long['label'],\n",
    "        y=-df_long['score'],\n",
    "        fillcolor='rgba(108, 140, 200, 0.3)',\n",
    "        line=dict(color='rgba(108, 140, 200, 1)'),\n",
    "        boxpoints='all',\n",
    "        jitter=0,\n",
    "        pointpos=0,\n",
    "        marker=dict(color='rgba(108, 140, 200, 1)')\n",
    "    ))\n",
    "    fig.update_yaxes(range=[0, max(-df_long['score'])*1.05])\n",
    "    fig.update_layout(\n",
    "        title='CV '+str(i_outer), yaxis_title='Validation Fitness',\n",
    "        width=1000, height=400,\n",
    "        plot_bgcolor='#f1f1f1',\n",
    "        xaxis_tickangle=-90,\n",
    "        margin=dict(l=50, r=50, t=50, b=20),\n",
    "        showlegend=False\n",
    "    )\n",
    "    fig.show()\n",
    "    \n",
    "    # Outer CV update\n",
    "    i_outer +=1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "181bee5f-bb99-4b4d-a1f5-e9900090d99a",
   "metadata": {},
   "outputs": [],
   "source": [
    "best_grid_models"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4bf48a0b-4ffe-4e0a-b4b5-f08833f5a444",
   "metadata": {},
   "source": [
    "<br />\n",
    "<hr />\n",
    "\n",
    "# Excercises\n",
    "\n",
    "- Try different ranges for the algorithms' hyperparameters.\n",
    "- Compare validation and test results. Tip: look at `df_test_set` and `validation_results` objects.\n",
    "- **Implement the nested cross-validation loop for SVM or RF without using the KFold method from** `scikit-learn`.\n",
    "\n",
    "<br />"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b84a3c76-daee-4851-be84-0352c1b66c76",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.12 nel_project",
   "language": "python",
   "name": "nel_project_py312"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
